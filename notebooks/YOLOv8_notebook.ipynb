{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FyRdDYkqAKN4"
   },
   "source": [
    "## Before you start\n",
    "\n",
    "Let's make sure that we have access to GPU. We can use `nvidia-smi` command to do that. In case of any problems navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator`, set it to `GPU`, and then click `Save`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check Teh GPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y8cDtxLIBHgQ",
    "outputId": "df71379d-a3bd-4add-ef60-3534e789dbe8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CjpPg4mGKc1v",
    "outputId": "0bab628e-b03e-4956-b769-d4aaae50a664"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "HOME = os.getcwd()\n",
    "print(HOME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colab connection with the drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FWNqvAE1HJ8S",
    "outputId": "ceab4ab9-3982-4807-947f-5384fba507f8"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3C3EO_2zNChu"
   },
   "source": [
    "## Install YOLOv8\n",
    "\n",
    "⚠️ YOLOv8 is still under heavy development. Breaking changes are being introduced almost weekly. We strive to make our YOLOv8 notebooks work with the latest version of the library. Last tests took place on **27.01.2023** with version **YOLOv8.0.20**.\n",
    "\n",
    "If you notice that our notebook behaves incorrectly - especially if you experience errors that prevent you from going through the tutorial - don't hesitate! Let us know and open an [issue](https://github.com/roboflow/notebooks/issues) on the Roboflow Notebooks repository.\n",
    "\n",
    "YOLOv8 can be installed in two ways - from the source and via pip. This is because it is the first iteration of YOLO to have an official package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install ththe yolo8 librart from ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tdSMcABDNKW-",
    "outputId": "4a760d36-0af7-4044-9cfa-c918b0e8adf5"
   },
   "outputs": [],
   "source": [
    "# Pip install method (recommended)\n",
    "\n",
    "!pip install ultralytics==8.0.20\n",
    "\n",
    "from IPython import display\n",
    "display.clear_output()\n",
    "\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iVvaIYEEPOty"
   },
   "outputs": [],
   "source": [
    "!Git clone method (for development)\n",
    "\n",
    "#%cd {HOME}\n",
    "!git clone github.com/ultralytics/ultralytics\n",
    "%cd {HOME}/ultralytics\n",
    "!pip install -e .\n",
    "\n",
    "from IPython import display\n",
    "display.clear_output()\n",
    "\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VOEYrlBoP9-E"
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "from IPython.display import display, Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This Augemntation code is for bounding box with 4 co-ordinates "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Augment the images using the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wXODBuMHDrtq"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "#def histogram_equalization(image):\n",
    "    # Convert image to grayscale\n",
    " #   gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply histogram equalization\n",
    "  #  equalized = cv2.equalizeHist(gray)\n",
    "\n",
    "    # Convert back to BGR color space\n",
    "   # equalized_image = cv2.cvtColor(equalized, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    #return equalized_image\n",
    "\n",
    "#def adjust_brightness(image, value):\n",
    "    # Convert image to HSV color space\n",
    " #   hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Adjust brightness\n",
    "  #  hsv[..., 2] = cv2.add(hsv[..., 2], value)\n",
    "\n",
    "    # Convert back to BGR color space\n",
    "   # brightness_adjusted = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    #return brightness_adjusted\n",
    "\n",
    "def horizontal_flip(image, annotations):\n",
    "    flipped = cv2.flip(image, 1)\n",
    "    flipped_annotations = [(class_id, 1 - x, y, width, height) for class_id, x, y, width, height in annotations]\n",
    "    return flipped, flipped_annotations\n",
    "\n",
    "def vertical_flip(image, annotations):\n",
    "    flipped = cv2.flip(image, 0)\n",
    "    flipped_annotations = [(class_id, x, 1 - y, width, height) for class_id, x, y, width, height in annotations]\n",
    "    return flipped, flipped_annotations\n",
    "\n",
    "\n",
    "def parse_yolo_annotation(annot_path):\n",
    "    with open(annot_path, 'r') as f:\n",
    "        lines = f.read().splitlines()\n",
    "\n",
    "    annotations = []\n",
    "    for line in lines:\n",
    "        class_id, x, y, width, height = map(float, line.split())\n",
    "        annotations.append((class_id, x, y, width, height))\n",
    "\n",
    "    return annotations\n",
    "\n",
    "def save_yolo_annotation(annot_path, annotations):\n",
    "    with open(annot_path, 'w') as f:\n",
    "        for annotation in annotations:\n",
    "            class_id, x, y, width, height = annotation\n",
    "            line = f\"{int(class_id)} {x} {y} {width} {height}\"\n",
    "            f.write(line + '\\n')\n",
    "\n",
    "# Define the input directory containing the original images\n",
    "input_dir = '/home/buddhad'\n",
    "\n",
    "# Define the input directory containing the original YOLO annotations\n",
    "annotation_dir = '/home/buddhadev/Downloads/Nair/annotations_corrected/labels'\n",
    "\n",
    "# Define the output directory to save augmented images\n",
    "output_dir = '/home/buddhadev/Downloads/Nair/annotations_corrected/aug_images'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Define the output directory to save augmented YOLO annotations\n",
    "aug_annotation_dir = '/home/buddhadev/Downloads/Nair/annotations_corrected/aug_lables'\n",
    "os.makedirs(aug_annotation_dir, exist_ok=True)\n",
    "\n",
    "# Define the categories and corresponding labels\n",
    "categories = [ 'horizontal_flip', 'vertical_flip' ]\n",
    "\n",
    "\n",
    "\n",
    "# Process each category\n",
    "for category in categories:\n",
    "    # Create a subdirectory for the category\n",
    "    category_dir = os.path.join(output_dir, category)\n",
    "    os.makedirs(category_dir, exist_ok=True)\n",
    "\n",
    "    # Create a subdirectory for the augmented annotations\n",
    "    aug_category_annot_dir = os.path.join(aug_annotation_dir, category)\n",
    "    os.makedirs(aug_category_annot_dir, exist_ok=True)\n",
    "\n",
    "    # Process each image in the input directory\n",
    "    for filename in os.listdir(input_dir):\n",
    "        image_path = os.path.join(input_dir, filename)\n",
    "\n",
    "        # Read the image\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        # Read the original annotation file\n",
    "        annotation_path = os.path.join(annotation_dir, f\"{os.path.splitext(filename)[0]}.txt\")\n",
    "        original_annotations = parse_yolo_annotation(annotation_path)\n",
    "\n",
    "        if  category == 'horizontal_flip':\n",
    "            # Apply horizontal flip\n",
    "            augmented_image, augmented_annotations = horizontal_flip(image, original_annotations)\n",
    "            # Update the filename and label\n",
    "            augmented_filename = f\"hor_flip_{filename}\"\n",
    "            label = f\"{filename}_hor_flip\"\n",
    "        elif category == 'vertical_flip':\n",
    "            # Apply vertical flip\n",
    "            augmented_image, augmented_annotations = vertical_flip(image, original_annotations)\n",
    "            # Update the filename and label\n",
    "            augmented_filename = f\"ver_flip_{filename}\"\n",
    "            label = f\"{filename}_ver_flip\"\n",
    "\n",
    "              # Calculate the new image dimensions\n",
    "            image_height, image_width, _ = augmented_image.shape\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        # Save the augmented image\n",
    "        augmented_image_path = os.path.join(category_dir, augmented_filename)\n",
    "        cv2.imwrite(augmented_image_path, augmented_image)\n",
    "\n",
    "        # Save the corresponding label file\n",
    "        label_file_path = os.path.join(aug_category_annot_dir, f\"{os.path.splitext(augmented_filename)[0]}.txt\")\n",
    "        with open(label_file_path, 'w') as f:\n",
    "            f.write(label)\n",
    "\n",
    "        # Save the corresponding augmented annotation file\n",
    "        aug_annotation_path = os.path.join(aug_category_annot_dir, f\"{os.path.splitext(augmented_filename)[0]}.txt\")\n",
    "        save_yolo_annotation(aug_annotation_path, augmented_annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This code is augmentation of Polygon whenre the co-ordianes are more than 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def horizontal_flip(image, annotations):\n",
    "    flipped = cv2.flip(image, 1)\n",
    "    flipped_annotations = [(class_id, [(1 - x, y) for x, y in points]) for class_id, points in annotations]\n",
    "    return flipped, flipped_annotations\n",
    "\n",
    "def vertical_flip(image, annotations):\n",
    "    flipped = cv2.flip(image, 0)\n",
    "    flipped_annotations = [(class_id, [(x, 1 - y) for x, y in points]) for class_id, points in annotations]\n",
    "    return flipped, flipped_annotations\n",
    "\n",
    "def parse_yolo_annotation(annot_path):\n",
    "    with open(annot_path, 'r') as f:\n",
    "        lines = f.read().splitlines()\n",
    "\n",
    "    annotations = []\n",
    "    for line in lines:\n",
    "        values = line.split()\n",
    "        class_id = int(values[0])\n",
    "        points = [(float(values[i]), float(values[i+1])) for i in range(1, len(values)-1, 2)]\n",
    "        annotations.append((class_id, points))\n",
    "\n",
    "    return annotations\n",
    "\n",
    "def save_yolo_annotation(annot_path, annotations):\n",
    "    with open(annot_path, 'w') as f:\n",
    "        for annotation in annotations:\n",
    "            class_id, points = annotation\n",
    "            points_str = \" \".join([f\"{x} {y}\" for x, y in points])\n",
    "            line = f\"{int(class_id)} {points_str}\"\n",
    "            f.write(line + '\\n')\n",
    "\n",
    "input_dir = '/home/buddhadev/Buddhadev_Everything/OPMD/YOLO_OPMD_SP/images'\n",
    "annotation_dir = '/home/buddhadev/Buddhadev_Everything/OPMD/YOLO_OPMD_SP/labels'\n",
    "output_dir = '/home/buddhadev/Buddhadev_Everything/OPMD/aug_images'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "aug_annotation_dir = '/home/buddhadev/Buddhadev_Everything/OPMD/aug_labels'\n",
    "os.makedirs(aug_annotation_dir, exist_ok=True)\n",
    "categories = ['horizontal_flip', 'vertical_flip']\n",
    "\n",
    "for category in categories:\n",
    "    category_dir = os.path.join(output_dir, category)\n",
    "    os.makedirs(category_dir, exist_ok=True)\n",
    "    aug_category_annot_dir = os.path.join(aug_annotation_dir, category)\n",
    "    os.makedirs(aug_category_annot_dir, exist_ok=True)\n",
    "\n",
    "    for filename in os.listdir(input_dir):\n",
    "        image_path = os.path.join(input_dir, filename)\n",
    "        image = cv2.imread(image_path)\n",
    "        annotation_path = os.path.join(annotation_dir, f\"{os.path.splitext(filename)[0]}.txt\")\n",
    "        original_annotations = parse_yolo_annotation(annotation_path)\n",
    "\n",
    "        if category == 'horizontal_flip':\n",
    "            augmented_image, augmented_annotations = horizontal_flip(image, original_annotations)\n",
    "            augmented_filename = f\"hor_flip_{filename}\"\n",
    "        elif category == 'vertical_flip':\n",
    "            augmented_image, augmented_annotations = vertical_flip(image, original_annotations)\n",
    "            augmented_filename = f\"ver_flip_{filename}\"\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        augmented_image_path = os.path.join(category_dir, augmented_filename)\n",
    "        cv2.imwrite(augmented_image_path, augmented_image)\n",
    "        aug_annotation_path = os.path.join(aug_category_annot_dir, f\"{os.path.splitext(augmented_filename)[0]}.txt\")\n",
    "        save_yolo_annotation(aug_annotation_path, augmented_annotations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OHRtPaY5GXE6",
    "outputId": "1232a6a3-750a-4d63-dad7-c4795516620d"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Function to copy files from source folder to destination folder\n",
    "def copy_files(source_folder, destination_folder):\n",
    "    for filename in os.listdir(source_folder):\n",
    "        source_path = os.path.join(source_folder, filename)\n",
    "        destination_path = os.path.join(destination_folder, filename)\n",
    "        shutil.copyfile(source_path, destination_path)\n",
    "\n",
    "# List of image folders and label folders\n",
    "image_folders = [\n",
    "    \"/home/buddhadev/Buddhadev_Everything/OPMD/YOLO_OPMD_SP/images\",\n",
    "    \"/home/buddhadev/Buddhadev_Everything/OPMD/aug_images/horizontal_flip\",\n",
    "    \"/home/buddhadev/Buddhadev_Everything/OPMD/aug_images/vertical_flip\"\n",
    "    \n",
    "\n",
    "]\n",
    "\n",
    "label_folders = [\n",
    "   \"/home/buddhadev/Buddhadev_Everything/OPMD/YOLO_OPMD_SP/labels\",\n",
    "    \"/home/buddhadev/Buddhadev_Everything/OPMD/aug_labels/horizontal_flip\",\n",
    "    \"/home/buddhadev/Buddhadev_Everything/OPMD/aug_labels/vertical_flip\"\n",
    "\n",
    "]\n",
    "\n",
    "# Create destination folders\n",
    "augmented_images_folder = \"/home/buddhadev/Buddhadev_Everything/OPMD/AUGEMENTATION/combined_images\"\n",
    "augmented_labels_folder = \"/home/buddhadev/Buddhadev_Everything/OPMD/AUGEMENTATION/combined_labels\"\n",
    "os.makedirs(augmented_images_folder, exist_ok=True)\n",
    "os.makedirs(augmented_labels_folder, exist_ok=True)\n",
    "\n",
    "# Copy images and labels to destination folders\n",
    "for folder in image_folders:\n",
    "    copy_files(folder, augmented_images_folder)\n",
    "\n",
    "for folder in label_folders:\n",
    "    copy_files(folder, augmented_labels_folder)\n",
    "\n",
    "print(\"Images and labels have been combined and stored in 'augmentedimagesnew' and 'augmentedlabelsnew' respectively.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HnnZSm5OQfPQ"
   },
   "source": [
    "## CLI Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K33S7zlkQku0"
   },
   "source": [
    "If you want to train, validate or run inference on models and don't need to make any modifications to the code, using YOLO command line interface is the easiest way to get started. Read more about CLI in [Ultralytics YOLO Docs](https://docs.ultralytics.com/usage/cli/).\n",
    "\n",
    "```\n",
    "yolo task=detect    mode=train    model=yolov8n.yaml      args...\n",
    "          classify       predict        yolov8n-cls.yaml  args...\n",
    "          segment        val            yolov8n-seg.yaml  args...\n",
    "                         export         yolov8n.pt        format=onnx  args...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fT1qD4toTTw0"
   },
   "source": [
    "### 💻 CLI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZaE1kLS8R4CV"
   },
   "source": [
    "`yolo mode=predict` runs YOLOv8 inference on a variety of sources, downloading models automatically from the latest YOLOv8 release, and saving results to `runs/predict`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AFMBYQtMVL-B"
   },
   "source": [
    "### 🐍 Python SDK\n",
    "\n",
    "The simplest way of simply using YOLOv8 directly in a Python environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u2Xtaekw3271"
   },
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6JHICVjZbVKn"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BSd93ZJzZZKt",
    "outputId": "40c99cf3-2dc1-4fdb-e619-6338ba33f9b6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2C5kpx0pIBn2"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "def split_data(images_dir, labels_dir, split_ratio):\n",
    "    # Create folders for train, test, and valid sets\n",
    "    os.makedirs('train/images', exist_ok=True)\n",
    "    os.makedirs('train/labels', exist_ok=True)\n",
    "    os.makedirs('test/images', exist_ok=True)\n",
    "    os.makedirs('test/labels', exist_ok=True)\n",
    "    os.makedirs('valid/images', exist_ok=True)\n",
    "    os.makedirs('valid/labels', exist_ok=True)\n",
    "\n",
    "    # Get a list of all image files\n",
    "    image_files = os.listdir(images_dir)\n",
    "\n",
    "    # Shuffle the image file list randomly\n",
    "    random.shuffle(image_files)\n",
    "\n",
    "    # Calculate the number of files for each set based on the split ratio\n",
    "    num_images = len(image_files)\n",
    "    num_train = int(num_images * split_ratio[0])\n",
    "    num_test = int(num_images * split_ratio[1])\n",
    "    num_valid = num_images - num_train - num_test\n",
    "\n",
    "    # Move files to their respective sets\n",
    "    for i, image_file in enumerate(image_files):\n",
    "        # Generate corresponding label file name\n",
    "        label_file = os.path.splitext(image_file)[0] + '.txt'\n",
    "\n",
    "        if i < num_train:\n",
    "            shutil.copy(os.path.join(images_dir, image_file), 'train/images')\n",
    "            shutil.copy(os.path.join(labels_dir, label_file), 'train/labels')\n",
    "        elif i < num_train + num_test:\n",
    "            shutil.copy(os.path.join(images_dir, image_file), 'test/images')\n",
    "            shutil.copy(os.path.join(labels_dir, label_file), 'test/labels')\n",
    "        else:\n",
    "            shutil.copy(os.path.join(images_dir, image_file), 'valid/images')\n",
    "            shutil.copy(os.path.join(labels_dir, label_file), 'valid/labels')\n",
    "\n",
    "# Example usage\n",
    "split_ratio = [0.8, 0.2]  # Train: 70%, Test: 15%, Valid: 15%\n",
    "images_dir = \"/home/buddhadev/Buddhadev_Everything/OPMD/AUGEMENTATION/combined_images\"\n",
    "labels_dir = \"/home/buddhadev/Buddhadev_Everything/OPMD/AUGEMENTATION/combined_labels\"\n",
    "\n",
    "split_data(images_dir, labels_dir, split_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SFwy2LEZMwhv",
    "outputId": "75baecd1-74f6-416f-80ce-400e129aa186"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Specify the directory containing the files you want to zip\n",
    "directory = '/content/drive/MyDrive/google_images'\n",
    "\n",
    "# Create a zip file in write mode\n",
    "zip_name = 'files.zip'\n",
    "zip_path = '/content/' + zip_name\n",
    "zipf = zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED)\n",
    "\n",
    "# Iterate over all files in the directory and add them to the zip file\n",
    "for foldername, subfolders, filenames in os.walk(directory):\n",
    "    for filename in filenames:\n",
    "        file_path = os.path.join(foldername, filename)\n",
    "        zipf.write(file_path, os.path.relpath(file_path, directory))\n",
    "\n",
    "# Close the zip file\n",
    "zipf.close()\n",
    "\n",
    "# Download the zip file\n",
    "from google.colab import files\n",
    "files.download(zip_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data into test train and valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dhYP1tDVIWYP"
   },
   "outputs": [],
   "source": [
    "`\n",
    "\n",
    "    # Calculate the number of files for each set\n",
    "    num_images = len(image_files)\n",
    "    num_train = int(num_images * 0.7)\n",
    "    num_valid = int(num_images * 0.15)\n",
    "    num_test = num_images - num_train - num_valid\n",
    "\n",
    "    # Move files to their respective sets\n",
    "    for i, image_file in enumerate(image_files):\n",
    "        # Generate corresponding label file name\n",
    "        label_file = os.path.splitext(image_file)[0] + '.txt'\n",
    "\n",
    "        if i < num_train:\n",
    "            shutil.copy(os.path.join(images_dir, image_file), 'train/images')\n",
    "            shutil.copy(os.path.join(labels_dir, label_file), 'train/labels')\n",
    "        elif i < num_train + num_valid:\n",
    "            shutil.copy(os.path.join(images_dir, image_file), 'valid/images')\n",
    "            shutil.copy(os.path.join(labels_dir, label_file), 'valid/labels')\n",
    "        else:\n",
    "            shutil.copy(os.path.join(images_dir, image_file), 'test/images')\n",
    "            shutil.copy(os.path.join(labels_dir, label_file), 'test/labels')\n",
    "\n",
    "# Example usage\n",
    "images_dir = '/content/newaugimage'\n",
    "labels_dir = '/content/newauglabel'\n",
    "\n",
    "split_data(images_dir, labels_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YUjFBKKqXa-u"
   },
   "source": [
    "## Custom Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D2YkphuiaE7_",
    "outputId": "2f88e651-f14d-47f7-fef4-20589ed2ea10",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#%cd {HOME}\n",
    "\n",
    "!yolo task=detect mode=train model=yolov8n.pt data=/home/buddhadev/Buddhadev_Everything/OPMD/data.yaml epochs=500 imgsz=640 plots=True patience=500 batch=32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1MScstfHhArr",
    "outputId": "e3008e76-3644-4595-dabc-8b90e0cb64c4"
   },
   "outputs": [],
   "source": [
    "!ls /content/runs/detect/train/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 484
    },
    "id": "_J35i8Ofhjxa",
    "outputId": "6630d636-1279-48ca-f927-d88ef15675a4"
   },
   "outputs": [],
   "source": [
    "#%cd {HOME}\n",
    "Image(filename=f'/home/buddhadev/Buddhadev_Everything/OPMD/runs/detect/train2/confusion_matrix.png', width=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "id": "A-urTWUkhRmn",
    "outputId": "3fc6e48c-62a7-470c-9a07-b31f4a42df63"
   },
   "outputs": [],
   "source": [
    "#%cd {HOME}\n",
    "Image(filename=f'/home/buddhadev/Buddhadev_Everything/OPMD/runs/detect/train2/results.png', width=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 463
    },
    "id": "HI4nADCCj3F5",
    "outputId": "107a0889-b37d-4542-a598-0c58436d45de"
   },
   "outputs": [],
   "source": [
    "%cd {HOME}\n",
    "Image(filename=f'/content/runs/segment/val/val_batch0_pred.jpg', width=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 634
    },
    "id": "q8GiCvq0WPpe",
    "outputId": "2e9602e8-9806-47f3-ab00-e4b5a2e07913"
   },
   "outputs": [],
   "source": [
    "%cd {HOME}\n",
    "Image(filename=f'/content/runs/segment/train/train_batch2.jpg', width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ODk1VTlevxn"
   },
   "source": [
    "## Validate Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YpyuwrNlXc1P",
    "outputId": "56328381-c369-4084-b21a-d556a3c82b4d"
   },
   "outputs": [],
   "source": [
    "%cd {HOME}\n",
    "\n",
    "!yolo task=detect mode=val model=/home/buddhadev/Buddhadev_Everything/OPMD/runs/detect/train6/weights/best.pt data=data.yaml source=data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"/home/buddhadev/Buddhadev_Everything/OPMD/runs/detect/train2/weights/best.pt\")\n",
    "model.train(data=\"data.yaml\", epochs=5)\n",
    "model.val()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i4eASbcWkQBq"
   },
   "source": [
    "## Inference with Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wjc1ctZykYuf",
    "outputId": "9029c9e0-d5d2-4005-d4d3-666d4458cca3",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#%cd {HOME}\n",
    "!yolo task=detect mode=predict model=/home/buddhadev/Buddhadev_Everything/OPMD/runs/detect/train2/weights/best.pt  conf=0.25 source=/home/buddhadev/Buddhadev_Everything/OPMD/test/images save=True plots=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mEYIo95n-I0S"
   },
   "source": [
    "**NOTE:** Let's take a look at few results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jbVjEtPAkz3j"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from IPython.display import Image, display\n",
    "\n",
    "for image_path in glob.glob(f'*.jpg')[:3]:\n",
    "      display(Image(filename=image_path, width=600))\n",
    "      print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# zip the content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "WnJXKl7-cp6g",
    "outputId": "082a4beb-57de-4eb0-e554-47e54b71b374"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Specify the directory containing the files you want to zip\n",
    "directory = '/content/runs'\n",
    "\n",
    "# Create a zip file in write mode\n",
    "zip_name = 'files.zip'\n",
    "zip_path = '/content/' + zip_name\n",
    "zipf = zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED)\n",
    "\n",
    "# Iterate over all files in the directory and add them to the zip file\n",
    "for foldername, subfolders, filenames in os.walk(directory):\n",
    "    for filename in filenames:\n",
    "        file_path = os.path.join(foldername, filename)\n",
    "        zipf.write(file_path, os.path.relpath(file_path, directory))\n",
    "\n",
    "# Close the zip file\n",
    "zipf.close()\n",
    "\n",
    "# Download the zip file\n",
    "from google.colab import files\n",
    "files.download(zip_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j0tsVilOCPyq"
   },
   "source": [
    "## Deploy model on Roboflow\n",
    "\n",
    "Once you have finished training your YOLOv8 model, you’ll have a set of trained weights ready for use. These weights will be in the `/runs/detect/train/weights/best.pt` folder of your project. You can upload your model weights to Roboflow Deploy to use your trained weights on our infinitely scalable infrastructure.\n",
    "\n",
    "The `.deploy()` function in the [Roboflow pip package](https://docs.roboflow.com/python) now supports uploading YOLOv8 weights.\n",
    "\n",
    "To upload model weights, add the following code to the “Inference with Custom Model” section in the aforementioned notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6EhBAJ2gCPZh",
    "outputId": "259decf5-1c4e-4011-a208-a2498acc30ca"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q5kOhjkmcV1l"
   },
   "outputs": [],
   "source": [
    "#While your deployment is processing, checkout the deployment docs to take your model to most destinations https://docs.roboflow.com/inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I4bpUIibcV1l"
   },
   "outputs": [],
   "source": [
    "#Run inference on your model on a persistant, auto-scaling, cloud API\n",
    "\n",
    "#load model\n",
    "model = project.version(dataset.version).model\n",
    "\n",
    "#choose random test set image\n",
    "import os, random\n",
    "test_set_loc = dataset.location + \"/test/images/\"\n",
    "random_test_image = random.choice(os.listdir(test_set_loc))\n",
    "print(\"running inference on \" + random_test_image)\n",
    "\n",
    "pred = model.predict(test_set_loc + random_test_image, confidence=40, overlap=30).json()\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def upscale_image(input_path, output_path, scale_factor=2, method=Image.BICUBIC):\n",
    "    \"\"\"\n",
    "    Upscale an image using the given method.\n",
    "    \n",
    "    Parameters:\n",
    "    - input_path (str): Path to the input image.\n",
    "    - output_path (str): Path to save the upscaled image.\n",
    "    - scale_factor (int): Factor by which to upscale the image.\n",
    "    - method (int): Interpolation method. Default is Image.BICUBIC.\n",
    "    \"\"\"\n",
    "    with Image.open(input_path) as img:\n",
    "        # Calculate new dimensions\n",
    "        width, height = img.size\n",
    "        new_dimensions = (width * scale_factor, height * scale_factor)\n",
    "        \n",
    "        # Resize the image\n",
    "        upscaled_img = img.resize(new_dimensions, method)\n",
    "        upscaled_img.save(output_path)\n",
    "\n",
    "def upscale_all_images_in_folder(input_folder, output_folder, scale_factor=2, method=Image.BICUBIC):\n",
    "    \"\"\"\n",
    "    Upscale all images in a folder using the given method.\n",
    "    \n",
    "    Parameters:\n",
    "    - input_folder (str): Path to the input folder containing images.\n",
    "    - output_folder (str): Path to save the upscaled images.\n",
    "    - scale_factor (int): Factor by which to upscale the image.\n",
    "    - method (int): Interpolation method. Default is Image.BICUBIC.\n",
    "    \"\"\"\n",
    "    # Ensure the output directory exists\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    # Iterate over all files in the directory\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.tiff', '.bmp', '.gif')):\n",
    "            input_path = os.path.join(input_folder, filename)\n",
    "            output_path = os.path.join(output_folder, filename)\n",
    "            \n",
    "            upscale_image(input_path, output_path, scale_factor, method)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_directory = input(\"Enter the path to the input folder containing images: \")\n",
    "    output_directory = input(\"Enter the path where upscaled images should be saved: \")\n",
    "    scale = int(input(\"Enter the scale factor (e.g., 2 for doubling the resolution): \"))\n",
    "    \n",
    "    upscale_all_images_in_folder(input_directory, output_directory, scale)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ovQgOj_xSNDg"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def has_two_in_first_column(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            columns = line.strip().split()  # Assuming space-separated columns\n",
    "            if columns and columns[0] == '2':\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def main(directory_path):\n",
    "    txt_files = [f for f in os.listdir(directory_path) if f.endswith('.txt')]\n",
    "    files_with_two = []\n",
    "\n",
    "    for txt_file in txt_files:\n",
    "        file_path = os.path.join(directory_path, txt_file)\n",
    "        if has_two_in_first_column(file_path):\n",
    "            files_with_two.append(txt_file)\n",
    "\n",
    "    return files_with_two\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    directory = input('Enter the path of the directory: ')\n",
    "    result = main(directory)\n",
    "    if result:\n",
    "        print('Files with number 2 in the first column:')\n",
    "        for filename in result:\n",
    "            print(filename)\n",
    "    else:\n",
    "        print('No such files found.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def replace_two_with_zero(file_path):\n",
    "    lines_to_write = []\n",
    "    replaced = False\n",
    "\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            columns = line.strip().split()  # Assuming space-separated columns\n",
    "\n",
    "            if columns and columns[0] == '2':\n",
    "                columns[0] = '0'\n",
    "                replaced = True\n",
    "\n",
    "            lines_to_write.append(\" \".join(columns))\n",
    "\n",
    "    if replaced:  # Only write back to the file if a replacement occurred\n",
    "        with open(file_path, 'w') as f:\n",
    "            f.write(\"\\n\".join(lines_to_write))\n",
    "\n",
    "def main(directory_path):\n",
    "    txt_files = [f for f in os.listdir(directory_path) if f.endswith('.txt')]\n",
    "\n",
    "    for txt_file in txt_files:\n",
    "        file_path = os.path.join(directory_path, txt_file)\n",
    "        replace_two_with_zero(file_path)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    directory = input('Enter the path of the directory: ')\n",
    "    main(directory)\n",
    "    print('Processing complete. Checked and replaced if necessary.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def rename_files_in_directory(directory_path):\n",
    "    try:\n",
    "        # List all files in the specified directory\n",
    "        files = [f for f in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, f))]\n",
    "\n",
    "        for file_name in files:\n",
    "            # Check if the file name contains a dash\n",
    "            if '-' in file_name:\n",
    "                # Split the file name at the dash and keep only the portion after the dash\n",
    "                new_file_name = file_name.split('-')[-1]\n",
    "\n",
    "                # Construct the full path for the old and new file names\n",
    "                old_file_path = os.path.join(directory_path, file_name)\n",
    "                new_file_path = os.path.join(directory_path, new_file_name)\n",
    "\n",
    "                # Rename the file\n",
    "                os.rename(old_file_path, new_file_path)\n",
    "                print(f'Renamed: {file_name} -> {new_file_name}')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Specify the directory path where the files are located\n",
    "directory_path = '/home/buddhadev/Buddhadev_Everything/OPMD/YOLO_OPMD_SP/labels'  # <-- REPLACE with your directory path\n",
    "rename_files_in_directory(directory_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the paths for the source images and labels\n",
    "source_images_dir = '/home/buddhadev/Buddhadev_Everything/OPMD/test/images'\n",
    "source_labels_dir = '/home/buddhadev/Buddhadev_Everything/OPMD/test/labels'\n",
    "\n",
    "# Define the paths for the destination train and validation directories\n",
    "train_images_dir = '/home/buddhadev/Buddhadev_Everything/OPMD/train/images'\n",
    "train_labels_dir = '/home/buddhadev/Buddhadev_Everything/OPMD/train/labels'\n",
    "valid_images_dir = '/home/buddhadev/Buddhadev_Everything/OPMD/valid/images'\n",
    "valid_labels_dir = '/home/buddhadev/Buddhadev_Everything/OPMD/valid/lables'\n",
    "\n",
    "# Create the destination directories if they don't exist\n",
    "os.makedirs(train_images_dir, exist_ok=True)\n",
    "os.makedirs(train_labels_dir, exist_ok=True)\n",
    "os.makedirs(valid_images_dir, exist_ok=True)\n",
    "os.makedirs(valid_labels_dir, exist_ok=True)\n",
    "\n",
    "# Get a list of image files in the source images directory\n",
    "image_files = glob(os.path.join(source_images_dir, '*.jpg'))  # Change '*.jpg' to match your image file types\n",
    "\n",
    "# Split the files into training and validation sets (70-30 split)\n",
    "train_files, valid_files = train_test_split(image_files, test_size=0.3, random_state=42)\n",
    "\n",
    "# Function to move files to their new directories\n",
    "def move_files(file_list, source_dir, dest_images_dir, dest_labels_dir):\n",
    "    for file_path in file_list:\n",
    "        base_name = os.path.basename(file_path)\n",
    "        label_file_name = os.path.splitext(base_name)[0] + '.txt'  # Change '.txt' to your label file extension\n",
    "        label_path = os.path.join(source_dir, label_file_name)\n",
    "\n",
    "        # Move the image\n",
    "        shutil.move(file_path, dest_images_dir)\n",
    "        \n",
    "        # Move the corresponding label file\n",
    "        shutil.move(label_path, dest_labels_dir)\n",
    "\n",
    "# Move the files to the respective train and valid directories\n",
    "move_files(train_files, source_labels_dir, train_images_dir, train_labels_dir)\n",
    "move_files(valid_files, source_labels_dir, valid_images_dir, valid_labels_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the paths for the source images and labels\n",
    "source_images_dir = '/home/buddhadev/Buddhadev_Everything/OPMD/test/images'\n",
    "source_labels_dir = '/home/buddhadev/Buddhadev_Everything/OPMD/test/labels'\n",
    "\n",
    "# Define the paths for the destination train and validation directories\n",
    "train_images_dir = '/home/buddhadev/Buddhadev_Everything/OPMD/train/images'\n",
    "train_labels_dir = '/home/buddhadev/Buddhadev_Everything/OPMD/train/labels'\n",
    "valid_images_dir = '/home/buddhadev/Buddhadev_Everything/OPMD/valid/images'\n",
    "valid_labels_dir = '/home/buddhadev/Buddhadev_Everything/OPMD/valid/lables'\n",
    "\n",
    "# Create the destination directories if they don't exist\n",
    "os.makedirs(train_images_dir, exist_ok=True)\n",
    "os.makedirs(train_labels_dir, exist_ok=True)\n",
    "os.makedirs(valid_images_dir, exist_ok=True)\n",
    "os.makedirs(valid_labels_dir, exist_ok=True)\n",
    "\n",
    "# Get a list of image files in the source images directory\n",
    "image_files = glob(os.path.join(source_images_dir, '*.jpg'))  # Change '*.jpg' to match your image file types\n",
    "\n",
    "# Debugging line to print out the full path being accessed\n",
    "print(f\"Accessing directory: {os.path.join(source_images_dir, '*.jpg')}\")\n",
    "\n",
    "# Get a list of image files in the source images directory\n",
    "image_files = glob(os.path.join(source_images_dir, '*.jpg'))  # Change '*.jpg' to match your image file types\n",
    "\n",
    "# Only proceed if image files were found\n",
    "if image_files:\n",
    "    # Split the files into training and validation sets (70-30 split)\n",
    "    train_files, valid_files = train_test_split(image_files, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Function to move files to their new directories\n",
    "    def move_files(file_list, source_dir, dest_images_dir, dest_labels_dir):\n",
    "        for file_path in file_list:\n",
    "            base_name = os.path.basename(file_path)\n",
    "            label_file_name = os.path.splitext(base_name)[0] + '.txt'  # Change '.txt' to your label file extension\n",
    "            label_path = os.path.join(source_dir, label_file_name)\n",
    "\n",
    "            # Move the image\n",
    "            shutil.move(file_path, dest_images_dir)\n",
    "            \n",
    "            # Move the corresponding label file\n",
    "            shutil.move(label_path, dest_labels_dir)\n",
    "\n",
    "    # Move the files to the respective train and valid directories\n",
    "    move_files(train_files, source_labels_dir, train_images_dir, train_labels_dir)\n",
    "    move_files(valid_files, source_labels_dir, valid_images_dir, valid_labels_dir)\n",
    "else:\n",
    "    print(\"No image files found. Please check the directory and file type.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the path to the directory containing images and labels\n",
    "data_directory = '/home/buddhadev/Buddhadev_Everything/OPMD/YOLO_OPMD_SP/'\n",
    "image_directory = os.path.join(data_directory, 'images')\n",
    "label_directory = os.path.join(data_directory, 'labels')\n",
    "\n",
    "# Create directories for the training and validation splits\n",
    "train_image_dir = os.path.join(data_directory, 'train_images')\n",
    "train_label_dir = os.path.join(data_directory, 'train_labels')\n",
    "valid_image_dir = os.path.join(data_directory, 'valid_images')\n",
    "valid_label_dir = os.path.join(data_directory, 'valid_labels')\n",
    "\n",
    "os.makedirs(train_image_dir, exist_ok=True)\n",
    "os.makedirs(train_label_dir, exist_ok=True)\n",
    "os.makedirs(valid_image_dir, exist_ok=True)\n",
    "os.makedirs(valid_label_dir, exist_ok=True)\n",
    "\n",
    "# Verify the directory exists and list files\n",
    "if os.path.exists(image_directory) and os.path.isdir(image_directory):\n",
    "    print(\"Image directory exists:\", image_directory)\n",
    "    all_files = os.listdir(image_directory)\n",
    "    print(f\"All files in directory: {all_files}\")  # This will print all files in the directory\n",
    "    image_files = [f for f in all_files if f.endswith(('.jpg', '.png'))]\n",
    "    print(f\"Found {len(image_files)} image files.\")\n",
    "else:\n",
    "    print(\"Image directory does not exist or is not a directory:\", image_directory)\n",
    "\n",
    "# Continue with the rest of the code if image files are found\n",
    "if image_files:\n",
    "    # Split the file names into training and validation sets\n",
    "    train_files, valid_files = train_test_split(image_files, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Function to copy image and label files to the respective directories\n",
    "    def copy_files(file_list, source_img_dir, dest_img_dir, source_lbl_dir, dest_lbl_dir):\n",
    "        for image_file in file_list:\n",
    "            base_filename = os.path.splitext(image_file)[0]\n",
    "            label_filename = base_filename + '.txt'\n",
    "\n",
    "            # Copy image\n",
    "            shutil.copy2(os.path.join(source_img_dir, image_file), os.path.join(dest_img_dir, image_file))\n",
    "            # Copy corresponding label\n",
    "            shutil.copy2(os.path.join(source_lbl_dir, label_filename), os.path.join(dest_lbl_dir, label_filename))\n",
    "\n",
    "    # Copy files to the train and validation directories\n",
    "    copy_files(train_files, image_directory, train_image_dir, label_directory, train_label_dir)\n",
    "    copy_files(valid_files, image_directory, valid_image_dir, label_directory, valid_label_dir)\n",
    "\n",
    "    print(f\"Training images and labels copied: {len(train_files)}\")\n",
    "    print(f\"Validation images and labels copied: {len(valid_files)}\")\n",
    "else:\n",
    "    print(\"No image files found, please check the directory and file permissions.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
